}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
}
# found current scale!
# let's use this scale for cauchy prior distribution
return(scale_current)
}
adjust_cauchy_scale(4.7854359796610275,1.5598297650412472,0.05145979448703311)
# do correction
library(BayesFactor)
library("oro.nifti")
# correcting Cauchy prior based on effect size and proportion of predicted positives
# inputs: contrast, noise (standard deviation, etc.), proportion of positives, percentile (e.g., .9? .95?)
# precision (default = 1e-9), max iterations (default = 10000)
# output: corrected Cauchy prior
# function to find
f <- function(x){
# pcauchy
# ES should be defined globally
# percentile should also be defined globally
fx<-pcauchy(ES,scale=x)-percentile
return(c(fx))
}
adjust_cauchy_scale<-function(contrast, noise, proportion, percentile = .9, precision = 1e-9, max_iter=10000)
{
# calculate average ES
ES <<- contrast / noise * proportion
# put percentile in global
percentile<<-percentile
# numerically estimate scale
# from 0 to 100, start from 50
now <- 50
from <- 0
to <- 100
iteration<-0
while(1){
iteration <- iteration + 1
# calculate pcauchy with the current scale
current <- f(now)
# difference?
if (abs(current) <= precision){
# within the boundary of the allowed precision. Stop
break
}
# if not, then move for 1/2
# if difference < 0, it indicates that the scale should increase
if (current >0){
from<-now
now <- (now + to)/2
}else{
# else, then the scale should decrease
to<-now
now <- (from + now)/2
}
# if iteration > max_iteration, stop
if (iteration >= max_iter){
break
}
}
# return iteration # and result
# if convergence failed then return -1
if (iteration >= max_iter){
return (-1)
}else{
return(now)
}
}
correct_scale<-function(filename_mask = 'mask.nii'){
# read mask file
MaskImg <- readNIfTI(filename_mask)
MaskImgData = oro.nifti::img_data(MaskImg)
# get mask size image
X <- dim(MaskImg)[1]
Y <- dim(MaskImg)[2]
Z <- dim(MaskImg)[3]
# let's count non-zero and non-nan voxel number
count <- 0
for (i in 1:X){
for (j in 1:Y){
for (k in 1:Z){
if ((MaskImgData[i,j,k] != 0) && !(is.nan(MaskImgData[i,j,k])) ){
# non zero and non nan -> count
count <- count + 1
}
}
}
}
# get combination (to find the # of comparison groups)
# find m where mC2 = total voxel number
# start from 2
config_scale <- .707
config_alpha <- .05
now <- 2
while(1){
# calculate current combination
combination <- now * (now-1)/2
# combination >= count (non-zero non-nan voxel #?)
if (combination >= count){
break
}
# the goal not achieved, then, increase 1
now <- now + 1
}
# finalize group number
Group <- now
# then, p(H01) = p(H0)^(2/m) where m = Group
# calculate the corrected threshold value
# .95 ^ (2/Group)
corr_p <- (1-config_alpha)^(2/Group)
# time to look for Cauchy distribution scale SCALE_NEW that satisfies
# pcauchy(qcauchy(.95,scale=.707), SCALE_NEW) = corr_p
default_point <- qcauchy((1-config_alpha),scale=config_scale)
# set desired precision
# default = (1-corr_p) / 10
precision <- (1-corr_p) / 10
# starting from the default scale .707
scale_default <- config_scale
scale_current <- scale_default
scale_previous <- scale_default
trial <- 1
while(1)
{
# until the precision is achieved...
# if first trial,
if (trial == 1)
{
# starting from the half of the default scale
scale_current <- scale_default / 2.0
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point, scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
else{
# if not the first trial...
# find the distance between current and previous scale
distance <- abs(scale_current - scale_previous)
# then, set the current scale as start_point + distance /2 * direction
# also, update the previous scale
scale_previous <- scale_current
scale_current <- scale_current + distance / 2.0 * direction
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point,scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
}
# found current scale!
# let's use this scale for cauchy prior distribution
return(scale_current)
}
adjust_cauchy_scale(4.7854359796610275,1.5598297650412472,0.05145979448703311)
adjust_cauchy_scale(2.337460017950926,0.09000875833726335,0.20115387840324436)
adjust_cauchy_scale(5.2238155142807825,2.337460017950926,0.09000875833726335)
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/Stress_aligned.RData")
table(data.filtered$residing_country)
length(table(data.filtered$residing_country))
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/Stress_aligned.RData")
length(table(data$residing_country))
length(table(data$UserLanguage))
length(table(data.mi$residing_country))
length(table(data.mi$UserLanguage))
length(table(data.filtered$residing_country))
length(table(data.filtered$UserLanguage))
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/Stress_aligned.RData")
table(data$gender)
10558+5009+163
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/Stress_aligned.RData")
colnames(data)
head(data[,88:104])
psych
library(psych)
psych::alpha(data[,88:95])
testmodel <- 'SI ~= socialinfluence_nor1_1 + socialinfluence_nor1_2'
testcfa(testmodel,data)
testcfa<-cfa(testmodel,data)
library(lavaan)
testcfa<-cfa(testmodel,data)
testmodel <- 'SI =~ socialinfluence_nor1_1 + socialinfluence_nor1_2'
testcfa<-cfa(testmodel,data)
testmodel <- 'SI =~ socialinfluence_nor1_1 + socialinfluence_nor1_2+socialinfluence_nor1_3+socialinfluence_nor1_4+socialinfluence_nor1_5+socialinfluence_nor1_6+socialinfluence_nor1_7+socialinfluence_nor1_8'
testcfa<-cfa(testmodel,data)
library(semTools)
runMI
test<-cfa.mi(testmodel,data = )
test<-cfa.mi(testmodel,data)
install.packages('Amelia')
test<-cfa.mi(testmodel,data)
test<-cfa.mi(testmodel,data,m=20)
head(data[,88:104])
testset<-data[,88:104]
head(testset)
testset<-data[,88:95]
head(testset)
test<-cfa.mi(testmodel,testset,m=20)
test
head(test@Data)
test@Data
test@Data@group
test<-cfa.mi(testmodel,testset,m=20,groups='UserLanguage')
test<-cfa.mi(testmodel,testset,m=20,group='UserLanguage')
test<-cfa.mi(testmodel,testset,m=20,miArgs = list(cs = "UserLanguage"))
testset<-data.filtered[,88:95]
head(testset)
test<-cfa.mi(testmodel,testset,m=20,miArgs = list(cs = "UserLanguage"))
testset<-data.filtered[,c(88:95,'UserLanguage')]
testset<-cbind(data.filtered[,c(88:95)],data.filtered$UserLanguage)
head(testset)
testset<-data.filtered[,c(88:95,'UserLanguage')]
test<-cfa.mi(testmodel,testset,m=20,miArgs = list(cs = "UserLanguage"))
class(testset)
test<-cfa.mi(testmodel,testset,m=20,miArgs = list(cs = "UserLanguage"))
test<-cfa.mi(testmodel,testset,m=20,miArgs = list(cs = "data.filtered$UserLanguage"))
test
summary(test)
fitMeasures(test)
test<-cfa.mi(testmodel,testset,estimator='WLSMV'm=20,miArgs = list(cs = "data.filtered$UserLanguage"))
test<-cfa.mi(testmodel,testset,estimator='WLSMV',m=20,miArgs = list(cs = "data.filtered$UserLanguage"))
fitMeasures(test)
test@Data@missing
summary(test@Data)
testamelia <- amelia(testset,m=20,cs='UserLanguage')
testamelia <- amelia(testset,m=20,cs='data.filtered$UserLanguage')
imps<-testamelia$imputations
head(imps)
head(testamelia$imputations$imp1)
head(testamelia$imputations$imp2)
AmeliaView()
a.out <- transform(testamelia)
head(a.out)
install.packages("Zelig")
load("~/Documents/GitHub/Identity-Project/Identity_aligned.RData")
testset<-data.filtered[,c(88:95,'UserLanguage')]
testset<-cbind(data.filtered[,c(88:95)],data.filtered$UserLanguage)
colnames(testset)
colnames(data.filtered)
testset<-cbind(data.filtered[,c(89:96)],data.filtered$UserLanguage)
testamelia <- amelia(testset,m=20,cs='data.filtered$UserLanguage')
for (i in 20){}
for (i in 20){
i<-1
tempdata <- cbind(testamelia$imputations[[i]],data.filtered$CS)
head(tempdata)
colnames(tempdata)[10] <- 'CS'
tempdata <- tempdata[,c(1:8,10)]
head(tempdata)
for (i in 20){
tempdata <- cbind(testamelia$imputations[[i]],data.filtered$CS)
colnames(tempdata)[10] <- 'CS'
tempdata <- tempdata[,c(1:8,10)]
ols.out <- lm(CS ~. , data=tempdata)
}
ols.out
summary(ols.out)
b.out <- NULL
se.out <- NULL
ols.out$coefficients
coef(summary(ols.out))[,2]
for (i in 20){
tempdata <- cbind(testamelia$imputations[[i]],data.filtered$CS)
colnames(tempdata)[10] <- 'CS'
tempdata <- tempdata[,c(1:8,10)]
ols.out <- lm(CS ~. , data=tempdata)
b.out <- rbind(b.out,ols.out$coefficients)
se.out <- rbind(se.out, coef(summary(ols.out))[,2])
}
b.out
se.out
for (i in 1:20){
tempdata <- cbind(testamelia$imputations[[i]],data.filtered$CS)
colnames(tempdata)[10] <- 'CS'
tempdata <- tempdata[,c(1:8,10)]
ols.out <- lm(CS ~. , data=tempdata)
b.out <- rbind(b.out,ols.out$coefficients)
se.out <- rbind(se.out, coef(summary(ols.out))[,2])
}
b.out
se.out
b.out <- NULL
se.out <- NULL
for (i in 1:20){
tempdata <- cbind(testamelia$imputations[[i]],data.filtered$CS)
colnames(tempdata)[10] <- 'CS'
tempdata <- tempdata[,c(1:8,10)]
ols.out <- lm(CS ~. , data=tempdata)
b.out <- rbind(b.out,ols.out$coefficients)
se.out <- rbind(se.out, coef(summary(ols.out))[,2])
}
combined.results <- mi.meld(q=b.out,se=se.out)
combined.results
testmodel
testmodel<-'
S1 =~ socialinfluence_nor1_1+socialinfluence_nor1_2+socialinfluence_nor1_3+
socialinfluence_nor1_4+socialinfluence_nor1_5+socialinfluence_nor1_6+
socialinfluence_nor1_7+socialinfluence_nor1_8
'
configural <- cfa.mi(testmodel,testset,group='data.filtered$UserLanguage',
estimator='WLSMV',m=20,seed=12345,
miArgs = list(noms = "data.filtered$UserLanguage"))
configural
summary(configural)
fitMeasures(configural)
configural <- cfa.mi(testmodel,testset,group='data.filtered$UserLanguage',
estimator='WLSMV',m=20,seed=12345
)
colnames(testset)
configural <- cfa.mi(testmodel,testset,group='data.filtered$UserLanguage',
estimator='WLSMV',m=20,seed=12345,
miArgs = list(x = testset[,1:8])
)
ameliadata <- amelia(testset,m=20,seed=12345,cs='data.filtered$UserLanguage')
configural <- cfa.mi(testmodel,ameliadata$imputations,group='data.filtered$UserLanguage',
estimator='WLSMV',m=20,seed=12345
)
configural <- cfa.mi(testmodel,ameliadata$imputations,group='data.filtered$UserLanguage',
estimator='MLR',m=20,seed=12345
)
fitmeasures(configural)
Fitmeasures(configural)
fitMeasures(configural)
fitMeasures(configural,test = "D2" , pool.robust = TRUE)
metric <- cfa.mi(testmodel,ameliadata$imputations,group='data.filtered$UserLanguage',
estimator='MLR',m=20,seed=12345, group.equal='loadings'
)
fitMeasures(configural,test = "D2" , pool.robust = TRUE)
fitMeasures(metric,test = "D2" , pool.robust = TRUE)
fitMeasures(metric)
scalar <- cfa.mi(testmodel,ameliadata$imputations,group='data.filtered$UserLanguage',
estimator='MLR',m=20,seed=12345, group.equal=c('loadings',
'intercepts')
)
fits.scalar<-fitMeasures(scalar)
fits.scalar
test <- plausibleValues(scalar)
test
test<-lavPredict(scalar)
scalar
summary(scalar)
class?lavaan.mi
test<-fitted(scalar)
test
test$EN
test<-fitted.values(scalar)
test
test <- plausibleValues(scalar)
test
test[[1]]
head(test[[1]])
head(test[[2]])
head(test[[3]])
head(test[[4]])
head(test[[5]])
head(test[[20]])
save.image("~/Documents/Research/Collaborations/COVID/Social_Norms/test.RData")
setwd("~/Documents/GitHub/COVIDiSTRESS2_Compliance/H1")
load("~/Documents/GitHub/COVIDiSTRESS2_Compliance/H1/H1.amelia.RData")
# H1
library(Amelia)
library(semTools)
test1 <- plausibleValues(scalar1,nDraws=1 )
test2 <- plausibleValues(scalar2,nDraws=1)
head(test1)
head(test1[[1]])
nrow(test1[[1]])
head(testset1[[1]])
head(testamelia1$imputations[[1]])
nrow(testamelia1$imputations[[1]])
# ID matching
data.H1 <- data[(testset.na < 6) & (testset.na2<6),]
head(data.H1$UserLanguage)
# ID matching
data.H1.temp <- data[(testset.na < 6) & (testset.na2<6),]
data.H1<-NULL
# match the ids
for (i in 1:20){
data.H1[[i]] <- data.H1.temp
data.H1[[i]]$S1 <- test1[[i]]$S1
data.H1[[i]]$S2 <- test2[[i]]$S2
}
library(psych)
# save all
save.image('H1.amelia.RData')
corr.test(data.H1[[1]]$S1,data.H1[[1]]$CS)
corr.test(data.H1[[1]]$S2,data.H1[[1]]$CS)
save(data.H1,file='H1.data.RData')
library(brms)
load('H1.data.RData')
b.test.0 <- brms::brm_multiple(CS ~ (1|country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415)
head(data.H1[[1]])
b.test.0 <- brms::brm_multiple(CS ~ (1|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415)
# random intercepts
b.test.1 <- brms::brm_multiple(CS ~ S1+S2+(1|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
# null model
prior.coef <- brms::prior(cauchy(0.,1),class='b')
# random intercepts
b.test.1 <- brms::brm_multiple(CS ~ S1+S2+(1|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
# standardize
for (i in 1:20){
data.H1[[i]]$CS <- scale(data.H1[[i]]$CS)
data.H1[[i]]$S1 <- scale(data.H1[[i]]$S1)
data.H1[[i]]$S2 <- scale(data.H1[[i]]$S2)
}
b.test.0 <- brms::brm_multiple(CS ~ (1|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415)
# random intercepts
b.test.1 <- brms::brm_multiple(CS ~ S1+S2+(1|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
# random slopes
b.test.2 <- brms::brm_multiple(CS ~ S1+S2+(1+S1+S2|residing_country),
data=data.H1, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bf.10 <- bayes_factor(b.test.1,b.test.0,log=T)
bf.20 <- bayes_factor(b.test.2,b.test.0,log=T)
bf.21 <- bayes_factor(b.test.2,b.test.1,log=T)
bf.21
bf.20
# save
save.image('H1.result.RData')
h.s2<- hypothesis(b.test.2,'S2=0')
# hypothesis testing
h.s1<- hypothesis(b.test.2,'S1=0')
h.s1
h.s2
h.s2$hypothesis
log(h.s2$hypothesis)
log(h.s2$hypothesis$Evid.Ratio)
log(h.s1$hypothesis$Evid.Ratio)
log(h.s2$hypothesis$Evid.Ratio)
hats<-round(b.test.2$rhats,3)[,1:9]
hats
describe(hats)
# save
save.image('H1.result.RData')
bf.10
bf.20
bf.21
log(h.s1$hypothesis$Evid.Ratio)
log(h.s2$hypothesis$Evid.Ratio)
h.s1
h.s2
load("~/Documents/GitHub/COVIDiSTRESS2_Compliance/H1/H1.amelia.RData")
rbind(fits.configural1[info],fits.configural2[info])
rbind(fits.metric1[info],fits.metric2[info])
rbind(fits.scalar1[info],fits.scalar2[info])
rbind(fits.metric1[info],fits.metric2[info])-rbind(fits.configural1[info],fits.configural2[info])
rbind(fits.scalar1[info],fits.scalar2[info])-rbind(fits.metric1[info],fits.metric2[info])
